{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1f_Jp6UDUPkirk1j4RaOnYIrmReG1hzDv",
      "authorship_tag": "ABX9TyO+0Pw6TMUe9rmkvFTTIF/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yang-star-source/Deep-Image-Prior/blob/master/Deep_Image_Prior_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Yang-star-source/Deep-Image-Prior.git"
      ],
      "metadata": {
        "id": "sGAbRi6otCRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPqNRMOsK_4B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,dropout_prob = 0.0 ):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(32,in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1,padding_mode='reflect')\n",
        "        self.norm2 = nn.GroupNorm(32,out_channels)\n",
        "        self.drop = nn.Dropout(dropout_prob)\n",
        "        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1,padding_mode='reflect')\n",
        "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Conv2d(in_channels,out_channels,kernel_size=1)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1 = x\n",
        "\n",
        "        x = self.norm1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = self.norm2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.conv2(x)\n",
        "        return x + self.shortcut(x1)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super().__init__()\n",
        "        self.res1 = ResNetBlock(in_channels,out_channels)\n",
        "        self.res2 = ResNetBlock(out_channels,out_channels)\n",
        "        self.down = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=2,padding=1,padding_mode='reflect')\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "\n",
        "        skip_connection = x\n",
        "\n",
        "        x = self.down(x)\n",
        "        return x , skip_connection\n",
        "\n",
        "class MidBlock(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.res1 = ResNetBlock(in_channels,in_channels)\n",
        "        self.res2 = ResNetBlock(in_channels,in_channels)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        return x\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(in_channels,in_channels,kernel_size=3,padding=1,padding_mode='reflect')\n",
        "        )\n",
        "        # Why input *2 ? Because we have to concatenate the channels\n",
        "        self.res1 = ResNetBlock(in_channels*2,out_channels)\n",
        "        self.res2 = ResNetBlock(out_channels,out_channels)\n",
        "\n",
        "    def forward(self,x,skip_connection):\n",
        "        x = self.up(x)\n",
        "\n",
        "        # cancatenate at channels dimension\n",
        "        x = torch.cat([x,skip_connection],dim=1)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,in_channels=3,out_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.init_conv = nn.Conv2d(in_channels,64,kernel_size=3,padding=1,padding_mode='reflect')\n",
        "\n",
        "        self.down1 = DownBlock(64,64)\n",
        "        self.down2 = DownBlock(64,128)\n",
        "        self.down3 = DownBlock(128,128)\n",
        "        self.down4 = DownBlock(128,256)\n",
        "\n",
        "        self.mid = MidBlock(256)\n",
        "\n",
        "        self.up1 = UpBlock(256,128)\n",
        "        self.up2 = UpBlock(128,128)\n",
        "        self.up3 = UpBlock(128,64)\n",
        "        self.up4 = UpBlock(64,64)\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.GroupNorm(32,64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64,out_channels,kernel_size=3,padding=1,padding_mode='reflect')\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        x1 , skip1 = self.down1(x)\n",
        "        x2 , skip2 = self.down2(x1)\n",
        "        x3 , skip3 = self.down3(x2)\n",
        "        x4 , skip4 = self.down4(x3)\n",
        "\n",
        "        x = self.mid(x4)\n",
        "\n",
        "        x = self.up1(x,skip4)\n",
        "        x = self.up2(x,skip3)\n",
        "        x = self.up3(x,skip2)\n",
        "        x = self.up4(x,skip1)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMAGE_PATH = \"/content/Deep-Image-Prior/images/0013.png\"\n",
        "img = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "img = transform(img)\n",
        "img = img.unsqueeze(0).to(DEVICE)\n",
        "print(img.shape)\n",
        "dataset_img = img\n",
        "\n",
        "def generate_mask(batch_size, channels, height, width,device):\n",
        "    \"\"\"\n",
        "    Generates a random box mask.\n",
        "    1 = Keep the pixel\n",
        "    0 = Drop the pixel (The Hole)\n",
        "    \"\"\"\n",
        "\n",
        "    mask = torch.ones((batch_size, 1, height, width), device=device)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        #mask[i, :, 108:149,108:149] = 0.0\n",
        "        #mask[i,:,151:180,151:180] = 0.0\n",
        "        mask[i,:,150:170,60:120] = 0.0\n",
        "\n",
        "    return mask\n",
        "\n",
        "def plottable_clean_img(img):\n",
        "    if img.dtype == torch.float32:\n",
        "        img = img.detach().cpu().squeeze(0).permute(1,2,0).numpy()\n",
        "        img = img * 0.5 + 0.5\n",
        "        img = np.clip(img,0,1)\n",
        "    return img\n",
        "\n",
        "mask = generate_mask(1,1,256,256,DEVICE)\n",
        "print(mask.shape)\n"
      ],
      "metadata": {
        "id": "AlC-mtKTLUJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "masked_img = img * mask\n",
        "plt.imshow(plottable_clean_img(masked_img))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YCi3ZAfOYNcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from IPython.display import clear_output\n",
        "\n",
        "EPOCH = 2000\n",
        "z = torch.randn_like(img).to(DEVICE)\n",
        "model = Unet().to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),lr=1e-4)\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "\n",
        "    recon = model(z)\n",
        "    loss = F.mse_loss(recon*mask,img*mask)\n",
        "\n",
        "    if epoch % 50 ==0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Epoch {epoch} Loss {loss.item()}\")\n",
        "        fig , (ax_dataset , ax_masked , ax_recon) = plt.subplots(1,3,figsize=(15,5))\n",
        "        ax_dataset.imshow(plottable_clean_img(dataset_img))\n",
        "        ax_masked.imshow(plottable_clean_img(masked_img))\n",
        "        ax_recon.imshow(plottable_clean_img(recon))\n",
        "        plt.show()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "0Ux8bEqXYbb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}